{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Self link: https://colab.research.google.com/drive/1BNok28YCY5ar8PCHUBGIrVzS1QS3vTDo?usp=sharing"
      ],
      "metadata": {
        "id": "x-E5ONqL2f6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZX7MG-eHZIy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "import onnxruntime\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_path = 'onnx_model.onnx'\n",
        "tf_path = 'tf_saved_model'\n",
        "tflite_path = 'tflite_model.tflite' # name of the output tflite model"
      ],
      "metadata": {
        "id": "k3_JaxaL8Ye4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load pytorch model\n",
        "\n",
        "Upload pytorch model in colab"
      ],
      "metadata": {
        "id": "-8-YK1N1S_gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved pytorch model\n",
        "model = torch.load('pytorch_model.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "# Input to the model with shape (1,3,300,300)\n",
        "x = torch.randn(1,3,300,300, requires_grad=True)\n",
        "\n",
        "# Output of the model used to validate results with onnx model\n",
        "torch_out = model(x)"
      ],
      "metadata": {
        "id": "834HmZ9kHh7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795eb7f0-468a-4dfa-a630-ed0e1f1f8799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Export pytorch model to onnx\n",
        "\n",
        "Executes the model, records a trace of what operators are used to compute the outputs. The input tensor ('x') is required to run the model, x can be random and must have the correct type and size"
      ],
      "metadata": {
        "id": "TIufawmITJsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.onnx.export(model, \n",
        "                  x,\n",
        "                  onnx_path,\n",
        "                  export_params=True,\n",
        "                  input_names=[\"input\"], \n",
        "                  output_names=[\"output\"])"
      ],
      "metadata": {
        "id": "8tFq1de0IOLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the ONNX model with ONNX's API \n",
        "\n",
        "Verify the model's structure and confirm that the model has a valid schema\n"
      ],
      "metadata": {
        "id": "L6mXLAfFT4-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Print a human readable representation of the graph\n",
        "# print(onnx.helper.printable_graph(model.graph))"
      ],
      "metadata": {
        "id": "wFZQKO6aT5Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test results of exported model with ONNXRuntime"
      ],
      "metadata": {
        "id": "wZ74slDRTYU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ort_session = onnxruntime.InferenceSession(onnx_path)\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results with the given precision\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6b9uFMULgwY",
        "outputId": "63a2db27-61d1-404b-ee10-3a366a095889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ewhXi6AF8q8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Export ONNX model to TF"
      ],
      "metadata": {
        "id": "aHM8xY0R7a0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(onnx_path)  # load onnx model\n",
        "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
        "tf_rep.export_graph(tf_path)  # export the model"
      ],
      "metadata": {
        "id": "nWqdihd9Sf11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bdec0c2-f738-4ea0-f59b-3cea00dea913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export TF model to TFLite"
      ],
      "metadata": {
        "id": "-sjVI7gh7gI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the tf model to tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(tf_path) # path to the SavedModel directory\n",
        "converter.optimizations = {tf.lite.Optimize.DEFAULT} # if size exceeds 40MB, try optimizing\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the tflite model.\n",
        "with open(tflite_path, 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "AaF_gL-c7kfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}